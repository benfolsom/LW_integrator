{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['gamma']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from scipy.special import j0, j1\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import itertools as itrt\n",
    "import matplotlib.pyplot as plt\n",
    "#%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_to_beta(gamma):\n",
    "    return sqrt(1-1/gamma**2)\n",
    "def kinetic_to_betagamma(energy, rest_energy):\n",
    "    gamma = energy/rest_energy+1\n",
    "    beta = gamma_to_beta(gamma)\n",
    "    return beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcount = 3\n",
    "m = 1.007319468  #amu\n",
    "c = 299.792458 # mm/ns\n",
    "q = 1.178734E-5 ##1.6E-19 C => 4.8032047E-10 statC [cm^(3/2)*g^(1/2)*s^(-1)] => [mm^(3/2)*amu^(1/2)*ns^(-1)];\n",
    "aperture = 500 #mm\n",
    "wall_pos = 30 #wall location on beam axis 'z', relative to origin\n",
    "\n",
    "\n",
    "Px = np.random.normal(-3e-2, 3e-2, pcount) #3e-2 amu*mm/ns corresponds to 93 keV\n",
    "Py = np.random.uniform(-3e-2, 3e-2, pcount)\n",
    "Pz = np.random.uniform(1e6, 1e6, pcount)  #  approx 1 TeV, CAREFUL WE ARE IN LAB FRAME HERE\n",
    "Pt = np.sqrt( Px**2+Py**2+Pz**2+m**2*c**2)\n",
    "gamma = Pt/(m*c)\n",
    "bx = Px/(gamma*m*c)\n",
    "by = Py/(gamma*m*c)\n",
    "bz = Pz/(gamma*m*c)\n",
    "beta_avg  = np.sqrt(bx**2+by**2+bz**2)\n",
    "\n",
    "x = numpy.random.uniform(-50, 50, pcount)\n",
    "y = numpy.random.uniform(-50, 50, pcount)\n",
    "z = numpy.random.uniform(-500, -450, pcount)\n",
    "t = numpy.random.normal(0, 100/(beta_avg*c), pcount) #from our old paper, not sure if this is necessary\n",
    "#t = numpy.zeros(pcount)\n",
    "\n",
    "bdotx = bx*np.random.uniform(-8e-1,8e-2)  #just a guess, there is probably much more acceleration going on in the core\n",
    "bdoty = by*np.random.uniform(-8e-2,8e-2) \n",
    "bdotz = bz*np.random.uniform(-8e-2,8e-2) #sloppy approximation to reflect much less deviation in logitudinal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999995, 0.99999995, 0.99999995])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([299.79244433, 299.79244433, 299.79244433])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_avg*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_beam = {'x':x, 'y':y, 'z':z, 't':t, 'Px':Px, 'Py':Py, 'Pz':Pz,'Pt':Pt,\n",
    "             'bx':bx,'by':by,'bz':bz,'bdotx':bdotx,'bdoty':bdoty,'bdotz':bdotz,'gamma':gamma,'q':q} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_rl = cp.deepcopy(init_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23.54038863,   6.89332564, -40.6129036 ])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_beam['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-457.52169361, -483.90274412, -498.71501901])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_beam['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallcount = pcount\n",
    "q_w = -q # one-to-one correlation for flat wall\n",
    "Px_w = np.zeros(wallcount)\n",
    "Py_w = np.zeros(wallcount)\n",
    "Pz_w = np.zeros(wallcount)  \n",
    "Pt_w = np.zeros(wallcount)\n",
    "gamma_w = np.zeros(wallcount)\n",
    "bx_w = np.zeros(wallcount)\n",
    "by_w = np.zeros(wallcount)\n",
    "bz_w = np.zeros(wallcount)\n",
    "beta_avg_w = np.sqrt(bx**2+by**2+bz**2)\n",
    "\n",
    "x_w = np.zeros(wallcount)\n",
    "y_w = np.zeros(wallcount)\n",
    "z_w = np.zeros(wallcount)\n",
    "t_w = np.zeros(wallcount)#????? we need to initialize to some common timestep, I think this is consistent (we operate completely in the lab frame throughout)\n",
    "\n",
    "bdotx_w = np.zeros(wallcount)  #just a guess, there is probably much more acceleration going on in the core\n",
    "bdoty_w = np.zeros(wallcount) \n",
    "bdotz_w = np.zeros(wallcount) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_wall = {'x':x_w, 'y':y_w, 'z':z_w, 't':t_w, 'Px':Px_w, 'Py':Py_w, 'Pz':Pz_w,'Pt':Pt_w,\n",
    "#             'bx':bx_w,'by':by_w,'bz':bz_w,'bdotx':bdotx_w,'bdoty':bdoty_w,'bdotz':bdotz_w,'gamma':gamma_w,'q':q_w} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bouncer_flat(vector,wall_Z,apt_R):\n",
    "    \"\"\" \n",
    "    taking losses at the circular aperture and generating a full image bunch reflecting off a flat wall\n",
    "    \n",
    "    includes cutoffs for particles striking wall or passing through the aperture\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    result['x'] = np.zeros_like(vector['x'])\n",
    "    result['y'] = np.zeros_like(vector['y'])\n",
    "    result['z'] = np.zeros_like(vector['z'])\n",
    "    result['t'] = np.zeros_like(vector['t'])\n",
    "    result['Px'] = np.zeros_like(vector['Px'])\n",
    "    result['Py'] = np.zeros_like(vector['Py'])\n",
    "    result['Pz'] = np.zeros_like(vector['Pz'])\n",
    "    result['Pt'] = np.zeros_like(vector['Pt'])\n",
    "    result['gamma'] = np.zeros_like(vector['gamma'])\n",
    "    result['bx'] = np.zeros_like(vector['bx'])\n",
    "    result['by'] = np.zeros_like(vector['by'])\n",
    "    result['bz'] = np.zeros_like(vector['bz'])\n",
    "    result['bdotx'] = np.zeros_like(vector['bdotx'])\n",
    "    result['bdoty'] =np.zeros_like(vector['bdoty'])\n",
    "    result['bdotz'] = np.zeros_like(vector['bdotz'])\n",
    "    result['q'] = vector['q']\n",
    "    for i in range(len(vector['x'])):\n",
    "        r = np.sqrt(vector['x'][i]**2+vector['y'][i]**2)\n",
    "        #sloppy way of taking losses, setting charge to zero\n",
    "        #if vector['z'][i]>=wall_Z and r>=apt_R:\n",
    "        #    vector['q'][i]=NaN #\n",
    "            \n",
    "        \n",
    "        #vector['z'][i]<wall_Z and r<=apt_R:\n",
    "        result['q']=-vector['q']\n",
    "        result['z'][i]=wall_Z + 2*(wall_Z-vector['z'][i])\n",
    "        result['x'][i]=vector['x'][i]\n",
    "        result['y'][i]=vector['y'][i]\n",
    "        result['Px'][i]=vector['Px'][i]\n",
    "        result['Py'][i]=vector['Py'][i]\n",
    "        result['Pz'][i]=-vector['Pz'][i]\n",
    "        result['Pt'][i]=vector['Pt'][i] #right?\n",
    "        result['gamma'][i]=vector['gamma'][i] \n",
    "        result['bx'][i]=vector['bx'][i] \n",
    "        result['by'][i]=vector['by'][i]\n",
    "        result['bz'][i]=-vector['bz'][i] \n",
    "        result['bdotx'][i]=vector['bdotx'][i] \n",
    "        result['bdoty'][i]=vector['bdoty'][i] \n",
    "        result['bdotz'][i]=-vector['bdotz'][i] \n",
    "        result['t'][i]=vector['t'][i]   #do NOT retard here, image charge is made to exist at the moment the original charge is created\n",
    " \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-457.52169361, -483.90274412, -498.71501901])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_beam['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_img = bouncer_flat(init_beam,wall_pos,aperture) \n",
    "#external_particle = ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-457.52169361, -483.90274412, -498.71501901])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_beam['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-457.52169361, -483.90274412, -498.71501901])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_rl['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4751472 , -0.02042117, -0.30191797])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_img['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chrono_matcher(vector_set,vector_ext_set,index_global_t,index_particle):\n",
    "#     \"\"\" \n",
    "#     scans back though external particle histories to find matching time point for sample particle and \n",
    "    \n",
    "#     Times are all in lab-frame. vector_set and vector_ext_set are full trajectories. index_global_t is the current time step\n",
    "#     ONLY WORKS FOR ONE SAMPLE PARTICLE AT A TIME -- But generates matched times for all particles in the corresponding image bunch \n",
    "#     \"\"\"\n",
    "#     vector_ext_set_matched = copy(vector_ext_set)\n",
    "#     if index==0:\n",
    "#         raise Exception('vector_ext_set must have a history -- cannot begin at t=0')\n",
    "        \n",
    "#     #rudimentary scan, should be as close to zero as possible, but just overshooting by a time step should be conservative enough for now.\n",
    "#     for j in range(len(vector_ext_set[index]['t'])):            \n",
    "#             k = 1\n",
    "#             while vector_set[index_global_t]['t'][index_particle]-vector_ext_set[index_global_t-k]['t'][j] > 0.1:\n",
    "#                 k += 1\n",
    "#             else:\n",
    "#                 vector_ext_set_matched[index]['t'][j] = vector_ext_set[index-k]['t'][j]\n",
    "            \n",
    "# return(vector_ext_set_matched)        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_euclid(vector,vector_ext,index):\n",
    "    \"\"\"\n",
    "    simple Euclidean distance generator with our standard retarded-potential notation\n",
    "    \n",
    "    requires chrono_match-ed trajectories\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    result['R'] = np.zeros_like(vector['x'])    \n",
    "    result['nx'] = np.zeros_like(vector['x'])\n",
    "    result['ny'] = np.zeros_like(vector['x'])    \n",
    "    result['nz'] = np.zeros_like(vector['x'])    \n",
    "    for j in range(len(vector_ext['x'])):\n",
    "        result['R'][j] = np.sqrt( (vector['x'][index]-vector_ext['x'][j])**2+\n",
    "                          (vector['y'][index]-vector_ext['y'][j])**2+\n",
    "                          (vector['z'][index]-vector_ext['z'][j])**2 )\n",
    "        result['nx'][j] = (vector['x'][index]-vector_ext['x'][j])/result['R'][j]\n",
    "        result['ny'][j] = (vector['y'][index]-vector_ext['y'][j])/result['R'][j]\n",
    "        result['nz'][j] = (vector['z'][index]-vector_ext['z'][j])/result['R'][j]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqsofmotion_static(h, vector,vector_ext): # nhat includes R and fnhat components, need to generate this per particle pair\n",
    "    result = {}\n",
    "    result['x'] = np.zeros_like(vector['x'])\n",
    "    result['y'] = np.zeros_like(vector['y'])\n",
    "    result['z'] = np.zeros_like(vector['z'])\n",
    "    result['t'] = np.zeros_like(vector['t'])\n",
    "    result['Px'] = np.zeros_like(vector['Px'])\n",
    "    result['Py'] = np.zeros_like(vector['Py'])\n",
    "    result['Pz'] = np.zeros_like(vector['Pz'])\n",
    "    result['Pt'] = np.zeros_like(vector['Pt'])\n",
    "    result['gamma'] = np.zeros_like(vector['gamma'])\n",
    "    result['bx'] = np.zeros_like(vector['bx'])\n",
    "    result['by'] = np.zeros_like(vector['by'])\n",
    "    result['bz'] = np.zeros_like(vector['bz'])\n",
    "    result['bdotx'] = np.zeros_like(vector['bdotx'])\n",
    "    result['bdoty'] =np.zeros_like(vector['bdoty'])\n",
    "    result['bdotz'] = np.zeros_like(vector['bdotz'])\n",
    "    result['q'] = vector['q']\n",
    "    for i in range(len(vector['x'])):   #iterating over all real particles OR all reflection points (these must be done in separate steps)            \n",
    "        nhat = dist_euclid(vector,vector_ext,i)\n",
    "        for j in range(len(vector_ext['x'])): #summing all external contributions (reflected particles and/or local particles)\n",
    "            #b_nhat = vector['bx'][i]*nhat['nx'][j]+vector['by'][i]*nhat['ny'][j]+vector['bz'][i]*nhat['nz'][j] #for accurate chrono-matching\n",
    "            result['x'][i] = vector['x'][i]\n",
    "            result['y'][i] = vector['y'][i]\n",
    "            result['z'][i] = vector['z'][i]\n",
    "            result['t'][i] = vector['t'][i]\n",
    "            result['Px'][i] = vector['Px'][i] + h/m*vector['q']*vector_ext['q']*vector['gamma'][i]\\\n",
    "                        *1/(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*vector['bx'][i]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        -nhat['nx'][j]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        /(vector_ext['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['nx'][j]/(c*nhat['R'][j])*(np.dot((vector['bx'][i],vector['by'][i],vector['bz'][i]),((vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])+vector_ext['gamma'][j]**2\\\n",
    "                        *np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])) ) ) ) ) )\n",
    "            result['Py'][i] = vector['Py'][i] + h/m*vector['q']*vector_ext['q']*vector['gamma'][i]\\\n",
    "                        *1/(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*vector['by'][i]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        -nhat['ny'][j]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        /(vector_ext['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['ny'][j]/(c*nhat['R'][j])*(np.dot((vector['bx'][i],vector['by'][i],vector['bz'][i]),((vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])+vector_ext['gamma'][j]**2\\\n",
    "                        *np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])) ) ) ) ) )\n",
    "            result['Pz'][i] = vector['Pz'][i] + h/m*vector['q']*vector_ext['q']*vector['gamma'][i]\\\n",
    "                        *1/(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*vector['bz'][i]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        -nhat['nz'][j]*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector['bx'][i],vector['by'][i],vector['bz'][i]))\\\n",
    "                        /(vector_ext['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['nz'][j]/(c*nhat['R'][j])*(np.dot((vector['bx'][i],vector['by'][i],vector['bz'][i]),((vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])+vector_ext['gamma'][j]**2\\\n",
    "                        *np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])) ) ) ) ) )\n",
    "            result['Pt'][i] = vector['Pt'][i] + h/m*vector['q']*vector_ext['q']*vector['gamma'][i] \\\n",
    "                        *(((vector_ext['gamma'][j]**2*np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(vector_ext['bdotx'][j],vector_ext['bdoty'][j],vector_ext['bdotz'][j])))/(c*nhat['R'][j]) \\\n",
    "                        - 1/nhat['R'][j]**2) /(1 - np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\n",
    "            result['gamma'][i] = result['Pt'][i]/(m*c)\n",
    "            result['bx'][i] = result['Px'][i]/(m*c*result['gamma'][i])\n",
    "            result['by'][i] = result['Py'][i]/(m*c*result['gamma'][i])\n",
    "            result['bz'][i] = result['Pz'][i]/(m*c*result['gamma'][i])\n",
    "            result['bdotx'][i] = (result['Px'][i]-vector['Px'][i]) / h   #necessary history to treat as an external particle later (keep in lab frame?) \n",
    "            result['bdoty'][i] =(result['Py'][i]-vector['Py'][i]) / h\n",
    "            result['bdotz'][i] = (result['Pz'][i]-vector['Pz'][i]) / h\n",
    "            \n",
    "            #NOTE---- Momentum values below are updated 'result', implicit technically, but only needs explicit solver for extreme \n",
    "            result['x'][i] = vector['x'][i] + h/m * (result['Px'][i]+vector['q']/c*vector_ext['q']*vector_ext['bx'][j]\\\n",
    "                        / (vector_ext['gamma'][j]*c*nhat['R'][j]*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result['y'][i] = vector['y'][i] + h/m * (result['Py'][i]+vector['q']/c*vector_ext['q']*vector_ext['by'][j]\\\n",
    "                        / (vector_ext['gamma'][j]*c*nhat['R'][j]*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result['z'][i] = vector['z'][i] + h/m * (result['Pz'][i]+vector['q']/c*vector_ext['q']*vector_ext['bz'][j]\\\n",
    "                        / (vector_ext['gamma'][j]*c*nhat['R'][j]*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result['t'][i] = vector['t'][i] + h/m * (result['Pt'][i]+vector['q']/c*vector_ext['q']\\\n",
    "                        / (vector_ext['gamma'][j]*c*nhat['R'][j]*(1-np.dot((vector_ext['bx'][j],vector_ext['by'][j],vector_ext['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_integrator(steps,h_step,bunch_real,wall_Z,apt_R):\n",
    "    trajectory      = [{}]*steps\n",
    "    trajectory_img  = [{}]*steps\n",
    "    for i in range(steps):\n",
    "        if i==0:\n",
    "            trajectory[i] = init_beam\n",
    "            trajectory_img[i] = bouncer_flat(init_beam,wall_Z,apt_R) #note that init_wall is a dummy vector\n",
    "        else:\n",
    "            trajectory[i] = eqsofmotion_static(h_step,trajectory[i-1],trajectory_img[i-1])\n",
    "            trajectory_img[i] = bouncer_flat(trajectory[i],wall_Z,apt_R) #note that init_wall is a dummy vector\n",
    "    return trajectory,trajectory_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermalized_bunch,thermalized_img = static_integrator(300,1.3E-6, init_beam,wall_pos,aperture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chron_matcher(traj_rl,traj_img,nhat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([ 23.54038863,   6.89332564, -40.6129036 ]),\n",
       " 'y': array([ 27.71666746, -48.03611048,  30.66345474]),\n",
       " 'z': array([-457.52169361, -483.90274412, -498.71501901]),\n",
       " 't': array([ 0.4751472 , -0.02042117, -0.30191797]),\n",
       " 'Px': array([-0.05148072, -0.05498809,  0.01412652]),\n",
       " 'Py': array([ 0.01174733, -0.02681457,  0.02746711]),\n",
       " 'Pz': array([1000000., 1000000., 1000000.]),\n",
       " 'Pt': array([1000000.04559801, 1000000.04559801, 1000000.04559801]),\n",
       " 'bx': array([-5.14807175e-08, -5.49880863e-08,  1.41265162e-08]),\n",
       " 'by': array([ 1.17473264e-08, -2.68145676e-08,  2.74671075e-08]),\n",
       " 'bz': array([0.99999995, 0.99999995, 0.99999995]),\n",
       " 'bdotx': array([ 6.29667162e-09,  6.72566233e-09, -1.72783205e-09]),\n",
       " 'bdoty': array([-8.21552022e-10,  1.87528307e-09, -1.92091859e-09]),\n",
       " 'bdotz': array([-0.06058842, -0.06058842, -0.06058842]),\n",
       " 'gamma': array([3311.40339291, 3311.40339291, 3311.40339291]),\n",
       " 'q': 1.178734e-05}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([ 23.54036923,   6.89330459, -40.61289815]),\n",
       " 'y': array([ 27.71667198, -48.03612111,  30.66346533]),\n",
       " 'z': array([ -71.64610878,  -98.02715373, -112.84124308]),\n",
       " 't': array([386.35078291, 385.85520343, 385.57733556]),\n",
       " 'Px': array([-0.05025043, -0.05454121,  0.01412652]),\n",
       " 'Py': array([ 0.01169082, -0.02755488,  0.02746711]),\n",
       " 'Pz': array([999999.97075364, 999999.98540612, 999995.21717976]),\n",
       " 'Pt': array([1000000.10411691, 1000000.07481149, 1000009.61131415]),\n",
       " 'gamma': array([3311.40358669, 3311.40348965, 3311.43506885]),\n",
       " 'bx': array([-5.02504282e-08, -5.45412049e-08,  1.41263811e-08]),\n",
       " 'by': array([ 1.16908143e-08, -2.75548749e-08,  2.74668447e-08]),\n",
       " 'bz': array([0.99999987, 0.99999991, 0.99998561]),\n",
       " 'bdotx': array([0., 0., 0.]),\n",
       " 'bdoty': array([0., 0., 0.]),\n",
       " 'bdotz': array([0., 0., 0.]),\n",
       " 'q': 1.178734e-05}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermalized_bunch[299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([ 23.54036923,   6.89330459, -40.61289815]),\n",
       " 'y': array([ 27.71667198, -48.03612111,  30.66346533]),\n",
       " 'z': array([233.29221755, 286.05430747, 315.68248616]),\n",
       " 't': array([386.35078291, 385.85520343, 385.57733556]),\n",
       " 'Px': array([-0.05025043, -0.05454121,  0.01412652]),\n",
       " 'Py': array([ 0.01169082, -0.02755488,  0.02746711]),\n",
       " 'Pz': array([-999999.97075364, -999999.98540612, -999995.21717976]),\n",
       " 'Pt': array([1000000.10411691, 1000000.07481149, 1000009.61131415]),\n",
       " 'gamma': array([3311.40358669, 3311.40348965, 3311.43506885]),\n",
       " 'bx': array([-5.02504282e-08, -5.45412049e-08,  1.41263811e-08]),\n",
       " 'by': array([ 1.16908143e-08, -2.75548749e-08,  2.74668447e-08]),\n",
       " 'bz': array([-0.99999987, -0.99999991, -0.99998561]),\n",
       " 'bdotx': array([0., 0., 0.]),\n",
       " 'bdoty': array([0., 0., 0.]),\n",
       " 'bdotz': array([-0., -0., -0.]),\n",
       " 'q': -1.178734e-05}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermalized_img[299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76570109, 1.27013272, 0.98863592])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thermalized_bunch[1]['t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delta_t = R/c*(1+beta_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrono_jn(trajectory,trajectory_ext):\n",
    "    for i in range(len(trajectory)):\n",
    "        for l in range(len(trajectory[i]['x'])):\n",
    "            nhat = dist_euclid(trajectory[i],trajectory_ext[i],l)\n",
    "            b_nhat = trajectory[i]['bx'][l]*nhat['nx'][j]+trajectory[i]['by'][l]*nhat['ny'][j]+trajectory[i]['bz'][l]*nhat['nz'][j] #for accurate chrono-matching\n",
    "            #b_nhat = trajectory[i]['bz'][l]*nhat['nz'][j] #for speedup\n",
    "            \n",
    "            delta_t = nhat['R']*(1+b_nhat)\n",
    "            t_ext_new = trajectory[i]['t'][l]-delta_t\n",
    "            \n",
    "            ####NOW MATCH\n",
    "            index_new=[]\n",
    "        \n",
    "    return(nhat,index_new)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqsofmotion_retarded(h, trajectory,trajectory_ext): # nhat includes R and fnhat components, need to generate this per particle pair\n",
    "    result = [{}]\n",
    "    for i in range(len(trajectory)):\n",
    "        result[i]['x'] = np.zeros_like(trajectory[i]['x'])\n",
    "        result[i]['y'] = np.zeros_like(trajectory[i]['y'])\n",
    "        result[i]['z'] = np.zeros_like(trajectory[i]['z'])\n",
    "        result[i]['t'] = np.zeros_like(trajectory[i]['t'])\n",
    "        result[i]['Px'] = np.zeros_like(trajectory[i]['Px'])\n",
    "        result[i]['Py'] = np.zeros_like(trajectory[i]['Py'])\n",
    "        result[i]['Pz'] = np.zeros_like(trajectory[i]['Pz'])\n",
    "        result[i]['Pt'] = np.zeros_like(trajectory[i]['Pt'])\n",
    "        result[i]['gamma'] = np.zeros_like(trajectory[i]['gamma'])\n",
    "        result[i]['bx'] = np.zeros_like(trajectory[i]['bx'])\n",
    "        result[i]['by'] = np.zeros_like(trajectory[i]['by'])\n",
    "        result[i]['bz'] = np.zeros_like(trajectory[i]['bz'])\n",
    "        result[i]['bdotx'] = np.zeros_like(trajectory[i]['bdotx'])\n",
    "        result[i]['bdoty'] =np.zeros_like(trajectory[i]['bdoty'])\n",
    "        result[i]['bdotz'] = np.zeros_like(trajectory[i]['bdotz'])\n",
    "        result[i]['q'] = trajectory[i]['q']\n",
    "    for l in range(len(trajectory[i]['x'])):   #iterating over all real particles OR all reflection points (these must be done in separate steps)            \n",
    "        nhat = dist_euclid(vector,vector_ext,l)\n",
    "        for j in range(len(trajectory_ext[i]['x'])): #summing all external contributions (reflected particles and/or local particles)\n",
    "            #b_nhat = trajectory[i]['bx'][l]*nhat['nx'][j]+trajectory[i]['by'][l]*nhat['ny'][j]+trajectory[i]['bz'][l]*nhat['nz'][j] #for accurate chrono-matching\n",
    "            result[i]['x'][l] = trajectory[i]['x'][l]\n",
    "            result[i]['y'][l] = trajectory[i]['y'][l]\n",
    "            result[i]['z'][l] = trajectory[i]['z'][l]\n",
    "            result[i]['t'][l] = trajectory[i]['t'][l]\n",
    "            result[i]['Px'][l] = trajectory[i]['Px'][l] + h/m*trajectory[i]['q']*trajectory_ext[i]['q']*trajectory[i]['gamma'][l]\\\n",
    "                        *1/(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*trajectory[i]['bx'][l]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        -nhat['nx'][j]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        /(trajectory_ext[i]['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['nx'][j]/(c*nhat['R'][j])*(np.dot((trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]),((trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])+trajectory_ext[i]['gamma'][j]**2\\\n",
    "                        *np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])) ) ) ) ) )\n",
    "            result[i]['Py'][l] = trajectory[i]['Py'][l] + h/m*trajectory[i]['q']*trajectory_ext[i]['q']*trajectory[i]['gamma'][l]\\\n",
    "                        *1/(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*trajectory[i]['by'][l]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        -nhat['ny'][j]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        /(trajectory_ext[i]['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['ny'][j]/(c*nhat['R'][j])*(np.dot((trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]),((trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])+trajectory_ext[i]['gamma'][j]**2\\\n",
    "                        *np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])) ) ) ) ) )\n",
    "            result[i]['Pz'][l] = trajectory[i]['Pz'][l] + h/m*trajectory[i]['q']*trajectory_ext[i]['q']*trajectory[i]['gamma'][l]\\\n",
    "                        *1/(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))**2)\\\n",
    "                        *( 1/nhat['R'][j]**2*trajectory[i]['bz'][l]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        -nhat['nz'][j]*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]))\\\n",
    "                        /(trajectory_ext[i]['gamma'][j]**2*nhat['R'][j]**2*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\\\n",
    "                        -nhat['nz'][j]/(c*nhat['R'][j])*(np.dot((trajectory[i]['bx'][l],trajectory[i]['by'][l],trajectory[i]['bz'][l]),((trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])+trajectory_ext[i]['gamma'][j]**2\\\n",
    "                        *np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])) ) ) ) ) )\n",
    "            result[i]['Pt'][l] = trajectory[i]['Pt'][l] + h/m*trajectory[i]['q']*trajectory_ext[i]['q']*trajectory[i]['gamma'][l] \\\n",
    "                        *(((trajectory_ext[i]['gamma'][j]**2*np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(trajectory_ext[i]['bdotx'][j],trajectory_ext[i]['bdoty'][j],trajectory_ext[i]['bdotz'][j])))/(c*nhat['R'][j]) \\\n",
    "                        - 1/nhat['R'][j]**2) /(1 - np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j]))))\n",
    "            result[i]['gamma'][l] = result[i]['Pt'][l]/(m*c)\n",
    "            result[i]['bx'][l] = result[i]['Px'][l]/(m*c*result[i]['gamma'][l])\n",
    "            result[i]['by'][l] = result[i]['Py'][l]/(m*c*result[i]['gamma'][l])\n",
    "            result[i]['bz'][l] = result[i]['Pz'][l]/(m*c*result[i]['gamma'][l])\n",
    "            result[i]['bdotx'][l] = (result[i]['Px'][l]-trajectory[i]['Px'][l]) / h   #necessary history to treat as an external particle later (keep in lab frame?) \n",
    "            result[i]['bdoty'][l] =(result[i]['Py'][l]-trajectory[i]['Py'][l]) / h\n",
    "            result[i]['bdotz'][l] = (result[i]['Pz'][l]-trajectory[i]['Pz'][l]) / h\n",
    "            \n",
    "            #NOTE---- Momentum values below are updated 'result', implicit technically, but only needs explicit solver for extreme \n",
    "            result[i]['x'][l] = trajectory[i]['x'][l] + h/m * (result[i]['Px'][l]+trajectory[i]['q']/c*trajectory_ext[i]['q']*trajectory_ext[i]['bx'][j]\\\n",
    "                        / (trajectory_ext[i]['gamma'][j]*c*nhat['R'][j]*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result[i]['y'][l] = trajectory[i]['y'][l] + h/m * (result[i]['Py'][l]+trajectory[i]['q']/c*trajectory_ext[i]['q']*trajectory_ext[i]['by'][j]\\\n",
    "                        / (trajectory_ext[i]['gamma'][j]*c*nhat['R'][j]*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result[i]['z'][l] = trajectory[i]['z'][l] + h/m * (result[i]['Pz'][l]+trajectory[i]['q']/c*trajectory_ext[i]['q']*trajectory_ext[i]['bz'][j]\\\n",
    "                        / (trajectory_ext[i]['gamma'][j]*c*nhat['R'][j]*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "            result[i]['t'][l] = trajectory[i]['t'][l] + h/m * (result[i]['Pt'][l]+trajectory[i]['q']/c*trajectory_ext[i]['q']\\\n",
    "                        / (trajectory_ext[i]['gamma'][j]*c*nhat['R'][j]*(1-np.dot((trajectory_ext[i]['bx'][j],trajectory_ext[i]['by'][j],trajectory_ext[i]['bz'][j]),(nhat['nx'][j],nhat['ny'][j],nhat['nz'][j])))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
